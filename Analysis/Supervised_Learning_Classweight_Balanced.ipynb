{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod5/Emoji_Analysis/Scripts/')\n",
    "import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "import emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "import xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "seed=42\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_tweet(tweet):\n",
    "    tweet = str(tweet).lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"‚Äù\",\"``\",\"‚Äú\",\"''\",\"‚Äô\",\"'s\",\"'re\",\"http\",\"https\", \"rt\"]\n",
    "alph = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "stopwords += alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_http(tweet):\n",
    "    pattern = '((http|https)\\w+\\s\\w+\\s\\w+\\s\\w+)'\n",
    "    try:\n",
    "        return tweet.replace(re.findall(pattern, tweet)[0][0], \"\")\n",
    "    except:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(tweet):\n",
    "    profane = pd.read_csv(\"profane_words.csv\", header=None)\n",
    "\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    tweet = tweet.lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spelling(tweet):\n",
    "    b = TextBlob(tweet)\n",
    "    return b.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(tweet):\n",
    "    b = TextBlob(tweet)\n",
    "    return b.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_username(tweet):\n",
    "    try:\n",
    "        p = '[\\w\\s]+(@\\w+)'\n",
    "        return tweet.replace(re.findall(p, tweet)[0], \"\")\n",
    "    except:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceThreeOrMore(tweet):\n",
    "    # pattern to look for three or more repetitions of any character, including\n",
    "    # newlines.\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL) \n",
    "    return pattern.sub(r\"\\1\\1\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(tweet):\n",
    "    tweet = remove_http(tweet)\n",
    "    tweet = remove_username(tweet)\n",
    "    tweet = ReplaceThreeOrMore(tweet)\n",
    "    tokens = process_tweet(tweet)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def return_sentiment(tweet):\n",
    "    return analyzer.polarity_scores(tweet)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load in Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>exclamation_points</th>\n",
       "      <th>top_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont want to vote for pedophile biden im sor...</td>\n",
       "      <td>-0.7447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I ll kidnap 1000 children before I let this co...</td>\n",
       "      <td>-0.2942</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg there s more on the ballot then just the p...</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am√©ricaniseUnTitre The Trump Tower Infernale</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biden will WIN Trump and DeJoy have cheated!! ...</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  i dont want to vote for pedophile biden im sor...          -0.7447   \n",
       "1  I ll kidnap 1000 children before I let this co...          -0.2942   \n",
       "2  omg there s more on the ballot then just the p...          -0.7003   \n",
       "3       Am√©ricaniseUnTitre The Trump Tower Infernale           0.4588   \n",
       "4  Biden will WIN Trump and DeJoy have cheated!! ...           0.5437   \n",
       "\n",
       "   exclamation_points top_emoji  \n",
       "0            0.000000         üò©  \n",
       "1            0.010101         üòä  \n",
       "2            0.000000         üò±  \n",
       "3            0.000000         üòä  \n",
       "4            0.021429         üòä  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets_4_classes.csv\").drop(['Unnamed: 0', 'emoji_frequency'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont want to vote for pedophile biden im sorry what\n",
      "dont want vote pedophile biden im sorry\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(df.tweet.iloc[0])\n",
    "print(clean_txt(df.tweet.iloc[0]))\n",
    "print(type(clean_txt(df.tweet.iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove \"http link stuff from all the tweets\"\n",
    "# print(df.tweet.iloc[0])\n",
    "# print(remove_http(df.tweet.iloc[0]))\n",
    "\n",
    "# df.tweet = df.tweet.apply(remove_http)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3654.000000\n",
       "mean        0.591639\n",
       "std         0.309474\n",
       "min         0.000000\n",
       "25%         0.290590\n",
       "50%         0.690462\n",
       "75%         0.871406\n",
       "max         1.000000\n",
       "Name: sentiment_score, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "normalizer = MinMaxScaler()\n",
    "df.sentiment_score = normalizer.fit_transform(np.array(df.sentiment_score).reshape(-1,1))\n",
    "df.sentiment_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3654/3654 [00:00<00:00, 7801.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>exclamation_points</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont want to vote for pedophile biden im sor...</td>\n",
       "      <td>0.126140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò©</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I ll kidnap 1000 children before I let this co...</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg there s more on the ballot then just the p...</td>\n",
       "      <td>0.148382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò±</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am√©ricaniseUnTitre The Trump Tower Infernale</td>\n",
       "      <td>0.729035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biden will WIN Trump and DeJoy have cheated!! ...</td>\n",
       "      <td>0.771566</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  i dont want to vote for pedophile biden im sor...         0.126140   \n",
       "1  I ll kidnap 1000 children before I let this co...         0.351818   \n",
       "2  omg there s more on the ballot then just the p...         0.148382   \n",
       "3       Am√©ricaniseUnTitre The Trump Tower Infernale         0.729035   \n",
       "4  Biden will WIN Trump and DeJoy have cheated!! ...         0.771566   \n",
       "\n",
       "   exclamation_points top_emoji  capitalization  \n",
       "0            0.000000         üò©        0.000000  \n",
       "1            0.010101         üòä        0.111111  \n",
       "2            0.000000         üò±        0.000000  \n",
       "3            0.000000         üòä        0.000000  \n",
       "4            0.021429         üòä        0.037037  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['capitalization'] = df.tweet.progress_apply(capital_percentage)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3654/3654 [00:07<00:00, 488.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>exclamation_points</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont want to vote for pedophile biden im sor...</td>\n",
       "      <td>0.126140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò©</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I ll kidnap 1000 children before I let this co...</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg there s more on the ballot then just the p...</td>\n",
       "      <td>0.148382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò±</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am√©ricaniseUnTitre The Trump Tower Infernale</td>\n",
       "      <td>0.729035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biden will WIN Trump and DeJoy have cheated!! ...</td>\n",
       "      <td>0.771566</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.007576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  i dont want to vote for pedophile biden im sor...         0.126140   \n",
       "1  I ll kidnap 1000 children before I let this co...         0.351818   \n",
       "2  omg there s more on the ballot then just the p...         0.148382   \n",
       "3       Am√©ricaniseUnTitre The Trump Tower Infernale         0.729035   \n",
       "4  Biden will WIN Trump and DeJoy have cheated!! ...         0.771566   \n",
       "\n",
       "   exclamation_points top_emoji  capitalization  profanity  \n",
       "0            0.000000         üò©        0.000000   0.000000  \n",
       "1            0.010101         üòä        0.111111   0.010753  \n",
       "2            0.000000         üò±        0.000000   0.000000  \n",
       "3            0.000000         üòä        0.000000   0.000000  \n",
       "4            0.021429         üòä        0.037037   0.007576  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['profanity'] = df.tweet.progress_apply(check_profanity)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3654/3654 [00:00<00:00, 5262.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df['subjectivity'] = df.tweet.progress_apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the replacing of extra chars\n",
    "test = \"yoooooo let's!! gooooo to the zoooo!. Wazzzzuppppp!!!. AAABBBCCC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yoo let's!! goo to the zoo!. Wazzupp!!. AABBCC\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReplaceThreeOrMore(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "üòä    2058\n",
       "üò©     831\n",
       "üò°     517\n",
       "üò±     248\n",
       "Name: top_emoji, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.top_emoji.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a very clear and large class imbalance. In this notebook, all models try to handle this inbalance by balancing the weights given to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ax = ['Happy', 'Sad', 'Angry', 'Fearful']\n",
    "y = df.top_emoji.value_counts()\n",
    "sns.barplot(x_ax, y)\n",
    "plt.title(\"Class Imbalance\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.savefig(\"../pics/class_imbalance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dummy Classifier for Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tweet', 'sentiment_score', 'capitalization', 'profanity','exclamation_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df['top_emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26053639846743293\n"
     ]
    }
   ],
   "source": [
    "dummy_cf = DummyClassifier(strategy='uniform')\n",
    "dummy_cf.fit(X['tweet'],y)\n",
    "y_preds = dummy_cf.predict(X['tweet'])\n",
    "\n",
    "print(dummy_cf.score(X['tweet'],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y, y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "results.append(('Dummy', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "üòä    2058\n",
       "üò©     831\n",
       "üò°     517\n",
       "üò±     248\n",
       "Name: top_emoji, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.top_emoji.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook uses class_weight = balanced, see other notebook for resampled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# cry = df[df.top_emoji == 'üò©']\n",
    "# happy = df[df.top_emoji == 'üòä']\n",
    "# fear = df[df.top_emoji == 'üò±']\n",
    "# anger = df[df.top_emoji == 'üò°']\n",
    "\n",
    "\n",
    "# cry_downsampled = resample(cry,\n",
    "#                           replace=False,\n",
    "#                           n_samples=int(len(fear)*1.5), # match number\n",
    "#                           random_state=seed) \n",
    "\n",
    "# happy_downsampled = resample(happy,\n",
    "#                           replace=False,\n",
    "#                           n_samples=int(len(fear)*1.5), # match number \n",
    "#                           random_state=seed) \n",
    "# fear_upsampled = resample(fear,\n",
    "#                           replace=True, \n",
    "#                           n_samples=int(len(fear)*1.5), # match number \n",
    "#                           random_state=seed) \n",
    "# anger_upsampled = resample(anger,\n",
    "#                           replace=True,\n",
    "#                           n_samples=int(len(fear)*1.5), # match number \n",
    "#                           random_state=seed) \n",
    "\n",
    "# df = pd.concat([cry_downsampled, happy_downsampled, fear_upsampled, anger_upsampled])\n",
    "# df.top_emoji.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tweet', 'sentiment_score', 'capitalization', 'profanity','exclamation_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df['top_emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        rs = []\n",
    "        for row in data.iterrows():\n",
    "            to_add = {}\n",
    "            for item in row[1:]:\n",
    "                for ind, val in zip(item.index, item.values):\n",
    "                    to_add[ind] = val\n",
    "            rs.append(to_add)\n",
    "        return rs\n",
    "#         return [{'cap':  row['capitalization'], 'prof': row['profanity'], \n",
    "#                  'sent': row['sentiment_score'], 'excla': row['exclamation_points']} for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ItemSelector(['capitalization','sentiment_score','exclamation_points']).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = []\n",
    "for row in test.transform(X).iterrows():\n",
    "    to_add = {}\n",
    "    for item in row[1:]:\n",
    "        for ind, val in zip(item.index, item.values):\n",
    "            to_add[ind] = val\n",
    "    rs.append(to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'capitalization': 0.0,\n",
       "  'sentiment_score': 0.12613966536419197,\n",
       "  'exclamation_points': 0.0},\n",
       " {'capitalization': 0.1111111111111111,\n",
       "  'sentiment_score': 0.35181845506462284,\n",
       "  'exclamation_points': 0.010101010101010102}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to help in the creation of our training arrays to include custom features as well as TF IDF and Word Embeddings.\n",
    "\n",
    "- NOTE: Word embeddings hurt the score, hence it is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(input_selectors): \n",
    "    pipeline = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for pulling features from the text\n",
    "                ('text', Pipeline([\n",
    "                    ('selector', ItemSelector(key='tweet')),\n",
    "                    ('tfidf', TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n",
    "                        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                        stop_words = None, preprocessor=clean_txt)),\n",
    "                ])),\n",
    "\n",
    "    #             ('embedding', Pipeline([\n",
    "    #                 ('selector', ItemSelector(key='tweet')),\n",
    "    #                 (\"mean_embeddings\", SpacyVectorTransformer(nlp))\n",
    "    #             ])),\n",
    "\n",
    "                # Pipeline for pulling metadata features\n",
    "                ('stats', Pipeline([\n",
    "                    ('selector', ItemSelector(key=input_selectors)),\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            transformer_weights={\n",
    "                'text': 1,#0.9,\n",
    "    #             'embedding': 1,\n",
    "                'stats': 1 #1.5,\n",
    "            },\n",
    "        ))\n",
    "    ], verbose=True)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['capitalization','profanity','sentiment_score','exclamation_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cap = create_pipeline(['capitalization'])\n",
    "pipeline_prof = create_pipeline(['profanity'])\n",
    "pipeline_sent = create_pipeline(['sentiment_score'])\n",
    "pipeline_excl = create_pipeline(['exclamation_points'])\n",
    "pipeline_all = create_pipeline(['capitalization','profanity','sentiment_score','exclamation_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   0.9s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   1.3s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   2.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   2.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union',\n",
       "                 FeatureUnion(transformer_list=[('text',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ItemSelector(key='tweet')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(max_df=0.2,\n",
       "                                                                                  min_df=3,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               2),\n",
       "                                                                                  preprocessor=<function clean_txt at 0x120902040>,\n",
       "                                                                                  smooth_idf=1,\n",
       "                                                                                  strip_accents='unicode',\n",
       "                                                                                  sublinear_tf=1,\n",
       "                                                                                  token_pattern='\\\\w{1,}',\n",
       "                                                                                  use_idf=1))])),\n",
       "                                                ('stats',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ItemSelector(key=['capitalization',\n",
       "                                                                                    'profanity',\n",
       "                                                                                    'sentiment_score',\n",
       "                                                                                    'exclamation_points'])),\n",
       "                                                                 ('stats',\n",
       "                                                                  TextStats()),\n",
       "                                                                 ('vect',\n",
       "                                                                  DictVectorizer())]))],\n",
       "                              transformer_weights={'stats': 1, 'text': 1}))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_cap.fit(X_train)\n",
    "pipeline_prof.fit(X_train)\n",
    "pipeline_sent.fit(X_train)\n",
    "pipeline_excl.fit(X_train)\n",
    "pipeline_all.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the shapes match: (2923, 2021) - (731, 2021)\n",
      "Checking that the shapes match: (2923, 2021) - (731, 2021)\n",
      "Checking that the shapes match: (2923, 2021) - (731, 2021)\n",
      "Checking that the shapes match: (2923, 2021) - (731, 2021)\n",
      "Checking that the shapes match: (2923, 2024) - (731, 2024)\n",
      "CPU times: user 7.54 s, sys: 70.5 ms, total: 7.61 s\n",
      "Wall time: 8.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_vec_cap = pipeline_cap.transform(X_train)\n",
    "test_vec_cap = pipeline_cap.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_cap.shape, test_vec_cap.shape))\n",
    "\n",
    "train_vec_prof = pipeline_prof.transform(X_train)\n",
    "test_vec_prof = pipeline_prof.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_prof.shape, test_vec_prof.shape))\n",
    "\n",
    "train_vec_sent = pipeline_sent.transform(X_train)\n",
    "test_vec_sent = pipeline_sent.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_sent.shape, test_vec_sent.shape))\n",
    "\n",
    "train_vec_excl = pipeline_excl.transform(X_train)\n",
    "test_vec_excl = pipeline_excl.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_excl.shape, test_vec_excl.shape))\n",
    "\n",
    "train_vec_all = pipeline_all.transform(X_train)\n",
    "test_vec_all = pipeline_all.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_all.shape, test_vec_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = [train_vec_cap, train_vec_prof, train_vec_sent, train_vec_excl, train_vec_all]\n",
    "tests = [test_vec_cap, test_vec_prof, test_vec_sent, test_vec_excl, test_vec_all]\n",
    "labels = ['capitalization', 'profanity', 'sentiment_score', 'exclamation_points', 'all_custom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Overarching Function for Iterative Modeling\n",
    "- Takes in a model\n",
    "- Runs that model against all the different train/test vecs with dif features\n",
    "- prints out accuracy and description of what train/test vec worked best\n",
    "- prints out confusion matrix and classification report for best version of the model\n",
    "- Returns best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(model, model_name, conditions=None, choices=None):\n",
    "    res = []\n",
    "    for train, test, label in zip(trains, tests, labels):\n",
    "        if type(model) == xgboost.sklearn.XGBClassifier:\n",
    "            model.fit(train, y_train, eval_metric='mlogloss', sample_weight = np.select(conditions, choices, None))\n",
    "        else:\n",
    "            model.fit(train, y_train)\n",
    "        test_preds = model.predict(test)\n",
    "        accuracy = accuracy_score(y_test, test_preds)\n",
    "        res.append({'label': label, 'score': accuracy, 'test_preds': test_preds})\n",
    "    res = sorted(res, key = lambda x: x['score'], reverse=True)\n",
    "    print('RESULTS')\n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    print(f\"{model_name} with {res[0]['label']} features performed the best with an accuracy of {res[0]['score']}\")\n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, res[0]['test_preds']))\n",
    "    print('----------------------------------------')\n",
    "    print(confusion_matrix(y_test, res[0]['test_preds']))\n",
    "    return res[0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to use in the optimization problem.\n",
    "\n",
    "    - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
    "      'saga' are faster for large ones.\n",
    "    - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
    "      handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
    "      schemes.\n",
    "    - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
    "      'liblinear' and 'saga' handle L1 penalty.\n",
    "    - 'liblinear' might be slower in LogisticRegressionCV because it does\n",
    "      not handle warm-starting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "log reg with all_custom features performed the best with an accuracy of 0.6990424076607387\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.90      0.89      0.89       412\n",
      "           üò°       0.41      0.39      0.40       103\n",
      "           üò©       0.51      0.56      0.53       166\n",
      "           üò±       0.26      0.22      0.24        50\n",
      "\n",
      "    accuracy                           0.70       731\n",
      "   macro avg       0.52      0.51      0.52       731\n",
      "weighted avg       0.70      0.70      0.70       731\n",
      "\n",
      "----------------------------------------\n",
      "[[367  12  31   2]\n",
      " [ 22  40  30  11]\n",
      " [ 19  36  93  18]\n",
      " [  1  10  28  11]]\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegressionCV(solver='newton-cg', cv=10, penalty='l2', Cs = [.001,.01,.1,1,10,100], \n",
    "                                    max_iter=10000, verbose=True, n_jobs=-1, scoring='f1', multi_class='ovr',\n",
    "                                class_weight='balanced')\n",
    "results.append(('log reg', get_model_results(lr_clf, 'log reg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514), ('log reg', 0.6990424076607387)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "linear svc with all_custom features performed the best with an accuracy of 0.7277701778385773\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.89      0.92      0.91       412\n",
      "           üò°       0.44      0.37      0.40       103\n",
      "           üò©       0.55      0.63      0.59       166\n",
      "           üò±       0.34      0.20      0.25        50\n",
      "\n",
      "    accuracy                           0.73       731\n",
      "   macro avg       0.56      0.53      0.54       731\n",
      "weighted avg       0.71      0.73      0.72       731\n",
      "\n",
      "----------------------------------------\n",
      "[[380   9  20   3]\n",
      " [ 23  38  37   5]\n",
      " [ 23  28 104  11]\n",
      " [  1  11  28  10]]\n"
     ]
    }
   ],
   "source": [
    "sv_clf = LinearSVC(C=1, class_weight='balanced', multi_class='ovr', random_state=seed) \n",
    "results.append(('linear svc', get_model_results(sv_clf, 'linear svc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "svc with all_custom features performed the best with an accuracy of 0.7400820793433652\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.89      0.92      0.91       412\n",
      "           üò°       0.47      0.37      0.42       103\n",
      "           üò©       0.55      0.66      0.60       166\n",
      "           üò±       0.56      0.28      0.37        50\n",
      "\n",
      "    accuracy                           0.74       731\n",
      "   macro avg       0.62      0.56      0.57       731\n",
      "weighted avg       0.73      0.74      0.73       731\n",
      "\n",
      "----------------------------------------\n",
      "[[380   6  25   1]\n",
      " [ 23  38  39   3]\n",
      " [ 23  27 109   7]\n",
      " [  1   9  26  14]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=15, class_weight='balanced', kernel='rbf', gamma='scale')\n",
    "results.append(('svc', get_model_results(svc, 'svc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('svc', 0.7400820793433652)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "rfc with all_custom features performed the best with an accuracy of 0.771545827633379\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.88      0.93      0.91       412\n",
      "           üò°       0.60      0.44      0.51       103\n",
      "           üò©       0.60      0.77      0.67       166\n",
      "           üò±       1.00      0.14      0.25        50\n",
      "\n",
      "    accuracy                           0.77       731\n",
      "   macro avg       0.77      0.57      0.58       731\n",
      "weighted avg       0.79      0.77      0.75       731\n",
      "\n",
      "----------------------------------------\n",
      "[[384   9  19   0]\n",
      " [ 22  45  36   0]\n",
      " [ 26  12 128   0]\n",
      " [  3   9  31   7]]\n"
     ]
    }
   ],
   "source": [
    "rfc_clf = RandomForestClassifier(n_estimators=400, random_state=seed,n_jobs=-1,\n",
    "                                 class_weight='balanced',criterion='entropy' )\n",
    "results.append(('rfc', get_model_results(rfc_clf, 'rfc')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('svc', 0.7400820793433652),\n",
       " ('rfc', 0.771545827633379)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MN Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "mn bayes with sentiment_score features performed the best with an accuracy of 0.5964432284541724\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.61      0.97      0.75       412\n",
      "           üò°       0.55      0.12      0.19       103\n",
      "           üò©       0.43      0.12      0.19       166\n",
      "           üò±       1.00      0.06      0.11        50\n",
      "\n",
      "    accuracy                           0.60       731\n",
      "   macro avg       0.64      0.32      0.31       731\n",
      "weighted avg       0.58      0.60      0.50       731\n",
      "\n",
      "----------------------------------------\n",
      "[[401   2   9   0]\n",
      " [ 82  12   9   0]\n",
      " [140   6  20   0]\n",
      " [ 36   2   9   3]]\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "mnb_clf = MultinomialNB() \n",
    "results.append(('mn bayes', get_model_results(mnb_clf, 'mn bayes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('svc', 0.7400820793433652),\n",
       " ('rfc', 0.771545827633379),\n",
       " ('mn bayes', 0.5964432284541724)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "bernoulli bayes with all_custom features performed the best with an accuracy of 0.6169630642954856\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.67      0.86      0.76       412\n",
      "           üò°       0.52      0.24      0.33       103\n",
      "           üò©       0.45      0.40      0.43       166\n",
      "           üò±       1.00      0.06      0.11        50\n",
      "\n",
      "    accuracy                           0.62       731\n",
      "   macro avg       0.66      0.39      0.41       731\n",
      "weighted avg       0.62      0.62      0.58       731\n",
      "\n",
      "----------------------------------------\n",
      "[[356  13  43   0]\n",
      " [ 54  25  24   0]\n",
      " [ 92   7  67   0]\n",
      " [ 29   3  15   3]]\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli Naive Bayes\n",
    "bb_clf = BernoulliNB() \n",
    "results.append(('bernoulli bayes', get_model_results(bb_clf, 'bernoulli bayes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('svc', 0.7400820793433652),\n",
       " ('rfc', 0.771545827633379),\n",
       " ('mn bayes', 0.5964432284541724),\n",
       " ('bernoulli bayes', 0.6169630642954856)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "pac with all_custom features performed the best with an accuracy of 0.6880984952120383\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.86      0.88      0.87       412\n",
      "           üò°       0.42      0.38      0.40       103\n",
      "           üò©       0.53      0.55      0.54       166\n",
      "           üò±       0.23      0.18      0.20        50\n",
      "\n",
      "    accuracy                           0.69       731\n",
      "   macro avg       0.51      0.50      0.50       731\n",
      "weighted avg       0.68      0.69      0.68       731\n",
      "\n",
      "----------------------------------------\n",
      "[[363  16  27   6]\n",
      " [ 26  39  29   9]\n",
      " [ 32  26  92  16]\n",
      " [  3  11  27   9]]\n"
     ]
    }
   ],
   "source": [
    "#PassiveAggresive Classifier\n",
    "pac_clf = PassiveAggressiveClassifier() \n",
    "results.append(('pac', get_model_results(pac_clf, 'pac')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('svc', 0.7400820793433652),\n",
       " ('rfc', 0.771545827633379),\n",
       " ('mn bayes', 0.5964432284541724),\n",
       " ('bernoulli bayes', 0.6169630642954856),\n",
       " ('pac', 0.6880984952120383)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "   y_train=='üòä', y_train=='üò©',y_train== 'üò°',y_train=='üò±'\n",
    "]\n",
    "\n",
    "choices = 1 / np.array(list(y_train.value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "xgboost with all_custom features performed the best with an accuracy of 0.7674418604651163\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.92      0.90      0.91       412\n",
      "           üò°       0.56      0.46      0.50       103\n",
      "           üò©       0.60      0.70      0.65       166\n",
      "           üò±       0.53      0.52      0.53        50\n",
      "\n",
      "    accuracy                           0.77       731\n",
      "   macro avg       0.65      0.65      0.65       731\n",
      "weighted avg       0.77      0.77      0.77       731\n",
      "\n",
      "----------------------------------------\n",
      "[[371  14  23   4]\n",
      " [ 16  47  35   5]\n",
      " [ 17  18 117  14]\n",
      " [  0   5  19  26]]\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_jobs=-1)\n",
    "results.append(('xgboost', get_model_results(xg, 'xgboost', conditions, choices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2651888341543514),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('svc', 0.7400820793433652),\n",
       " ('rfc', 0.771545827633379),\n",
       " ('mn bayes', 0.5964432284541724),\n",
       " ('bernoulli bayes', 0.6169630642954856),\n",
       " ('pac', 0.6880984952120383),\n",
       " ('xgboost', 0.7674418604651163)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "voting with all_custom features performed the best with an accuracy of 0.7414500683994528\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.85      0.94      0.90       412\n",
      "           üò°       0.54      0.37      0.44       103\n",
      "           üò©       0.57      0.64      0.60       166\n",
      "           üò±       0.53      0.20      0.29        50\n",
      "\n",
      "    accuracy                           0.74       731\n",
      "   macro avg       0.62      0.54      0.56       731\n",
      "weighted avg       0.72      0.74      0.72       731\n",
      "\n",
      "----------------------------------------\n",
      "[[388   5  19   0]\n",
      " [ 28  38  34   3]\n",
      " [ 36  18 106   6]\n",
      " [  2  10  28  10]]\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('logreg', lr_clf), ('svm_linear', sv_clf), ('pass_aggr', pac_clf),\n",
    "                            ('svc', svc), ('xgboost', xg), ('rfc', rfc_clf),\n",
    "                            ('mnbayes', mnb_clf),('berbayes', bb_clf)], #(\n",
    "                voting='hard', verbose=1, n_jobs= -1)\n",
    "results.append(('voting', get_model_results(voting_clf, 'voting')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rfc', 0.771545827633379),\n",
       " ('xgboost', 0.7674418604651163),\n",
       " ('voting', 0.7414500683994528),\n",
       " ('svc', 0.7400820793433652),\n",
       " ('linear svc', 0.7277701778385773),\n",
       " ('log reg', 0.6990424076607387),\n",
       " ('pac', 0.6880984952120383),\n",
       " ('bernoulli bayes', 0.6169630642954856),\n",
       " ('mn bayes', 0.5964432284541724),\n",
       " ('Dummy', 0.2651888341543514)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart of Different Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[0] for x in results]\n",
    "y = [x[1] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x,y)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Model Results\", fontsize=20)\n",
    "plt.savefig(\"../pics/model_performances.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
