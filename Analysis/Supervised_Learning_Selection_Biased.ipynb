{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod5/Emoji_Analysis/Scripts/')\n",
    "import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "import emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_tweet(tweet):\n",
    "    tweet = str(tweet).lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"‚Äù\",\"``\",\"‚Äú\",\"''\",\"‚Äô\",\"'s\",\"'re\",\"http\",\"https\"]\n",
    "alph = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "stopwords += alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_http(tweet):\n",
    "    pattern = '((http|https)\\w+\\s\\w+\\s\\w+\\s\\w+)'\n",
    "    try:\n",
    "        return tweet.replace(re.findall(pattern, tweet)[0][0], \"\")\n",
    "    except:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(tweet):\n",
    "    profane = pd.read_csv(\"profane_words.csv\", header=None)\n",
    "\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    tweet = tweet.lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spelling(tweet):\n",
    "    b = TextBlob(tweet)\n",
    "    return b.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(tweet):\n",
    "    tweet = remove_http(tweet)\n",
    "    tokens = process_tweet(tweet)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def return_sentiment(tweet):\n",
    "    return analyzer.polarity_scores(tweet)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load in Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>top_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello this has been KARINA and WINTER We re cu...</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ilysm you deserve the world please you re awes...</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey 965TDY I d like to hear Naughty List by li...</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I were to lift her up I d die SingleAndMing...</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Blair don t be a lier a Blier R G Mugabe RI...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>üòÇ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  Hello this has been KARINA and WINTER We re cu...           0.9840   \n",
       "1  ilysm you deserve the world please you re awes...           0.7284   \n",
       "2  Hey 965TDY I d like to hear Naughty List by li...           0.9168   \n",
       "3  If I were to lift her up I d die SingleAndMing...           0.9723   \n",
       "4  Mr Blair don t be a lier a Blier R G Mugabe RI...           0.4404   \n",
       "\n",
       "  top_emoji  \n",
       "0         üòä  \n",
       "1         üòç  \n",
       "2         üòä  \n",
       "3         üòÇ  \n",
       "4         üòÇ  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets_7_classes.csv\").drop(['Unnamed: 0', 'emoji_frequency'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello this has been KARINA and WINTER We re currently looking for our dearest member t https t co w9NXwy7G8b\n",
      "hello karina winter currently looking dearest member\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(df.tweet.iloc[0])\n",
    "print(clean_txt(df.tweet.iloc[0]))\n",
    "print(type(clean_txt(df.tweet.iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello this has been KARINA and WINTER We re currently looking for our dearest member t https t co w9NXwy7G8b\n",
      "Hello this has been KARINA and WINTER We re currently looking for our dearest member t \n"
     ]
    }
   ],
   "source": [
    "# # Remove \"http link stuff from all the tweets\"\n",
    "# print(df.tweet.iloc[0])\n",
    "# print(remove_http(df.tweet.iloc[0]))\n",
    "\n",
    "# df.tweet = df.tweet.apply(remove_http)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40462.000000\n",
       "mean         0.608406\n",
       "std          0.306372\n",
       "min          0.000000\n",
       "25%          0.329932\n",
       "50%          0.720230\n",
       "75%          0.885921\n",
       "max          1.000000\n",
       "Name: sentiment_score, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "df.sentiment_score = normalizer.fit_transform(np.array(df.sentiment_score).reshape(-1,1))\n",
    "df.sentiment_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40462/40462 [00:03<00:00, 10347.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello this has been KARINA and WINTER We re cu...</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ilysm you deserve the world please you re awes...</td>\n",
       "      <td>0.864266</td>\n",
       "      <td>üòç</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey 965TDY I d like to hear Naughty List by li...</td>\n",
       "      <td>0.958490</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I were to lift her up I d die SingleAndMing...</td>\n",
       "      <td>0.986247</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Blair don t be a lier a Blier R G Mugabe RI...</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  Hello this has been KARINA and WINTER We re cu...         0.992098   \n",
       "1  ilysm you deserve the world please you re awes...         0.864266   \n",
       "2  Hey 965TDY I d like to hear Naughty List by li...         0.958490   \n",
       "3  If I were to lift her up I d die SingleAndMing...         0.986247   \n",
       "4  Mr Blair don t be a lier a Blier R G Mugabe RI...         0.720230   \n",
       "\n",
       "  top_emoji  capitalization  \n",
       "0         üòä        0.100000  \n",
       "1         üòç        0.000000  \n",
       "2         üòä        0.133333  \n",
       "3         üòÇ        0.133333  \n",
       "4         üòÇ        0.176471  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['capitalization'] = df.tweet.progress_apply(capital_percentage)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40462/40462 [01:20<00:00, 501.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello this has been KARINA and WINTER We re cu...</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ilysm you deserve the world please you re awes...</td>\n",
       "      <td>0.864266</td>\n",
       "      <td>üòç</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey 965TDY I d like to hear Naughty List by li...</td>\n",
       "      <td>0.958490</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I were to lift her up I d die SingleAndMing...</td>\n",
       "      <td>0.986247</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Blair don t be a lier a Blier R G Mugabe RI...</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  Hello this has been KARINA and WINTER We re cu...         0.992098   \n",
       "1  ilysm you deserve the world please you re awes...         0.864266   \n",
       "2  Hey 965TDY I d like to hear Naughty List by li...         0.958490   \n",
       "3  If I were to lift her up I d die SingleAndMing...         0.986247   \n",
       "4  Mr Blair don t be a lier a Blier R G Mugabe RI...         0.720230   \n",
       "\n",
       "  top_emoji  capitalization  profanity  \n",
       "0         üòä        0.100000   0.000000  \n",
       "1         üòç        0.000000   0.000000  \n",
       "2         üòä        0.133333   0.000000  \n",
       "3         üòÇ        0.133333   0.014286  \n",
       "4         üòÇ        0.176471   0.000000  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['profanity'] = df.tweet.progress_apply(check_profanity)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet, sentiment_score, top_emoji, capitalization, profanity]\n",
       "Index: []"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dummy Classifier for Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df['top_emoji']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2160298551727547\n"
     ]
    }
   ],
   "source": [
    "dummy_cf = DummyClassifier()\n",
    "dummy_cf.fit(X['tweet'],y)\n",
    "y_preds = dummy_cf.predict(X['tweet'])\n",
    "\n",
    "print(dummy_cf.score(X['tweet'],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y, y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(('Dummy', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVM', 0.39317929074508834),\n",
       " ('RFC', 0.47053008773013716),\n",
       " ('MNBayes', 0.43346101569257384),\n",
       " ('BerBayes', 0.4286420363276906),\n",
       " ('Dummy', 0.21343482773960754)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        return [{'pos':  row['capitalization'], 'sub': row['profanity']} for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='tweet')),\n",
    "                ('tfidf', TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n",
    "                    strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                    ngram_range=(1, 10), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                    stop_words = None, preprocessor=clean_txt)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling metadata features\n",
    "            ('stats', Pipeline([\n",
    "                ('selector', ItemSelector(key=['capitalization', 'profanity'])),\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'text': 0.9,\n",
    "            'stats': 1.5,\n",
    "        },\n",
    "    ))\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "seed = 40\n",
    "X = df[['tweet', 'capitalization', 'profanity']]\n",
    "y =df['top_emoji']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   9.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union',\n",
       "                 FeatureUnion(transformer_list=[('text',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ItemSelector(key='tweet')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(max_df=0.2,\n",
       "                                                                                  min_df=3,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               10),\n",
       "                                                                                  preprocessor=<function clean_txt at 0x11fe12430>,\n",
       "                                                                                  smooth_idf=1,\n",
       "                                                                                  strip_accents='unicode',\n",
       "                                                                                  sublinear_tf=1,\n",
       "                                                                                  token_pattern='\\\\w{1,}',\n",
       "                                                                                  use_idf=1))])),\n",
       "                                                ('stats',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ItemSelector(key=['capitalization',\n",
       "                                                                                    'profanity'])),\n",
       "                                                                 ('stats',\n",
       "                                                                  TextStats()),\n",
       "                                                                 ('vect',\n",
       "                                                                  DictVectorizer())]))],\n",
       "                              transformer_weights={'stats': 1.5,\n",
       "                                                   'text': 0.9}))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the shapes match: (32369, 16899) - (8093, 16899)\n",
      "CPU times: user 10.5 s, sys: 22.8 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_vec = pipeline.transform(X_train)\n",
    "test_vec = pipeline.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec.shape, test_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "#Linear Support Vector Machines\n",
    "sv_clf = LinearSVC(C=1, class_weight='balanced', multi_class='ovr', random_state=40,verbose=3) \n",
    "sv_clf.fit(train_vec, y_train)\n",
    "test_preds = sv_clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC\n",
      "Testing Accuracy: 0.3932\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "print('Linear SVC')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "\n",
    "results.append(('SVM', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   37.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_clf = RandomForestClassifier(n_estimators=200,random_state=0,n_jobs=-1,verbose=1)\n",
    "rfc_clf.fit(train_vec, y_train)\n",
    "test_preds = rfc_clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Testing Accuracy: 0.4705\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "print('Random Forest')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "\n",
    "results.append(('RFC', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2201   43  203    5  251   52   35]\n",
      " [ 332   87  144    0   55   21    7]\n",
      " [ 516   34  655    1  173   40   20]\n",
      " [ 146    4   21   22   32    3    3]\n",
      " [ 952   19  229    5  501   23   15]\n",
      " [ 140    7   31    1   31  283    2]\n",
      " [ 518   12   61    2   83   13   59]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.79      0.58      2790\n",
      "           1       0.42      0.13      0.20       646\n",
      "           2       0.49      0.46      0.47      1439\n",
      "           3       0.61      0.10      0.16       231\n",
      "           4       0.44      0.29      0.35      1744\n",
      "           5       0.65      0.57      0.61       495\n",
      "           6       0.42      0.08      0.13       748\n",
      "\n",
      "    accuracy                           0.47      8093\n",
      "   macro avg       0.50      0.34      0.36      8093\n",
      "weighted avg       0.47      0.47      0.43      8093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, test_preds))\n",
    "print('----------------------------------------------------------------------------------------------------')\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes\n",
    "mnb_clf = MultinomialNB() \n",
    "mnb_clf.fit(train_vec, y_train)\n",
    "test_preds = mnb_clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN Bayes\n",
      "Testing Accuracy: 0.4335\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "print('MN Bayes')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "\n",
    "results.append(('MNBayes', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernoulli Naive Bayes\n",
    "bb_clf = BernoulliNB() \n",
    "bb_clf.fit(train_vec, y_train)\n",
    "test_preds = bb_clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Bayes\n",
      "Testing Accuracy: 0.4286\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "print('Bernoulli Bayes')\n",
    "print(\"Testing Accuracy: {:.4}\".format(accuracy))\n",
    "\n",
    "results.append(('BerBayes', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVM', 0.39317929074508834),\n",
       " ('RFC', 0.47053008773013716),\n",
       " ('MNBayes', 0.43346101569257384),\n",
       " ('BerBayes', 0.4286420363276906),\n",
       " ('Dummy', 0.21343482773960754)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[0] for x in results]\n",
    "y = [x[1] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x,y)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Early Results with Selection Biased Data\", fontsize=20)\n",
    "plt.savefig(\"/Users/brianmccabe/Desktop/Early_Results_Selection_Biased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
