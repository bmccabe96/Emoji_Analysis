{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/brianmccabe/DataScience/Flatiron/mod5/Emoji_Analysis/Scripts/')\n",
    "import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brianmccabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import scipy\n",
    "import emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "import xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "seed=42\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function that removes stopwords \n",
    "def process_tweet(tweet):\n",
    "    tweet = str(tweet).lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords and punctuations\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords += list(string.punctuation)\n",
    "stopwords += [\"n't\", \"' '\", \"'re'\",\"‚Äù\",\"``\",\"‚Äú\",\"''\",\"‚Äô\",\"'s\",\"'re\",\"http\",\"https\", \"rt\"]\n",
    "alph = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "stopwords += alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_http(tweet):\n",
    "    pattern = '((http|https)\\w+\\s\\w+\\s\\w+\\s\\w+)'\n",
    "    try:\n",
    "        return tweet.replace(re.findall(pattern, tweet)[0][0], \"\")\n",
    "    except:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_profanity(tweet):\n",
    "    profane = pd.read_csv(\"profane_words.csv\", header=None)\n",
    "\n",
    "    profane = list(profane.loc[:,0])\n",
    "    count = 0\n",
    "    tweet = tweet.lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    for word in tokens:\n",
    "        if word in profane:\n",
    "            count += 1\n",
    "    return count/len(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correct_spelling(tweet):\n",
    "#     b = TextBlob(tweet)\n",
    "#     return str(b.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_percentage(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    cap_count = 0\n",
    "    for item in tokens:\n",
    "        if item.isupper():\n",
    "            cap_count += 1\n",
    "    return cap_count/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(tweet):\n",
    "    b = TextBlob(tweet)\n",
    "    return b.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_username(tweet):\n",
    "    try:\n",
    "        p = '[\\w\\s]+(@\\w+)'\n",
    "        return tweet.replace(re.findall(p, tweet)[0], \"\")\n",
    "    except:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceThreeOrMore(tweet):\n",
    "    # pattern to look for three or more repetitions of any character, including\n",
    "    # newlines.\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL) \n",
    "    return pattern.sub(r\"\\1\\1\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(tweet):\n",
    "    tweet = remove_http(tweet)\n",
    "    tweet = remove_username(tweet)\n",
    "    tweet = ReplaceThreeOrMore(tweet)\n",
    "    tokens = process_tweet(tweet)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt_2(tweet):\n",
    "    tweet = remove_http(tweet)\n",
    "    tweet = remove_username(tweet)\n",
    "    tweet = ReplaceThreeOrMore(tweet)\n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def return_sentiment(tweet):\n",
    "    return analyzer.polarity_scores(tweet)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load in Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>exclamation_points</th>\n",
       "      <th>top_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont want to vote for pedophile biden im sor...</td>\n",
       "      <td>-0.7447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you need a President too I can be one for you ...</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D√¨ cheer! Cheeeeeeeeeeeeer! salvinisciacallo C...</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ll kidnap 1000 children before I let this co...</td>\n",
       "      <td>-0.2942</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>omg there s more on the ballot then just the p...</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò±</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  i dont want to vote for pedophile biden im sor...          -0.7447   \n",
       "1  you need a President too I can be one for you ...           0.4033   \n",
       "2  D√¨ cheer! Cheeeeeeeeeeeeer! salvinisciacallo C...           0.9690   \n",
       "3  I ll kidnap 1000 children before I let this co...          -0.2942   \n",
       "4  omg there s more on the ballot then just the p...          -0.7003   \n",
       "\n",
       "   exclamation_points top_emoji  \n",
       "0            0.000000         üò©  \n",
       "1            0.000000         üòä  \n",
       "2            0.014286         üòä  \n",
       "3            0.010101         üòä  \n",
       "4            0.000000         üò±  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets_4_classes.csv\").drop(['Unnamed: 0', 'emoji_frequency'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont want to vote for pedophile biden im sorry what\n",
      "dont want vote pedophile biden im sorry\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(df.tweet.iloc[0])\n",
    "print(clean_txt(df.tweet.iloc[0]))\n",
    "print(type(clean_txt(df.tweet.iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove \"http link stuff from all the tweets\"\n",
    "# print(df.tweet.iloc[0])\n",
    "# print(remove_http(df.tweet.iloc[0]))\n",
    "\n",
    "# df.tweet = df.tweet.apply(remove_http)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5019.000000\n",
       "mean        0.602604\n",
       "std         0.306544\n",
       "min         0.000000\n",
       "25%         0.307935\n",
       "50%         0.701232\n",
       "75%         0.872458\n",
       "max         1.000000\n",
       "Name: sentiment_score, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "normalizer = MinMaxScaler()\n",
    "df.sentiment_score = normalizer.fit_transform(np.array(df.sentiment_score).reshape(-1,1))\n",
    "df.sentiment_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5019/5019 [00:00<00:00, 5051.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>exclamation_points</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont want to vote for pedophile biden im sor...</td>\n",
       "      <td>0.126140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò©</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you need a President too I can be one for you ...</td>\n",
       "      <td>0.701232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D√¨ cheer! Cheeeeeeeeeeeeer! salvinisciacallo C...</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ll kidnap 1000 children before I let this co...</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>omg there s more on the ballot then just the p...</td>\n",
       "      <td>0.148382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò±</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  i dont want to vote for pedophile biden im sor...         0.126140   \n",
       "1  you need a President too I can be one for you ...         0.701232   \n",
       "2  D√¨ cheer! Cheeeeeeeeeeeeer! salvinisciacallo C...         0.984621   \n",
       "3  I ll kidnap 1000 children before I let this co...         0.351818   \n",
       "4  omg there s more on the ballot then just the p...         0.148382   \n",
       "\n",
       "   exclamation_points top_emoji  capitalization  \n",
       "0            0.000000         üò©        0.000000  \n",
       "1            0.000000         üòä        0.066667  \n",
       "2            0.014286         üòä        0.000000  \n",
       "3            0.010101         üòä        0.111111  \n",
       "4            0.000000         üò±        0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['capitalization'] = df.tweet.progress_apply(capital_percentage)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5019/5019 [00:15<00:00, 326.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>exclamation_points</th>\n",
       "      <th>top_emoji</th>\n",
       "      <th>capitalization</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont want to vote for pedophile biden im sor...</td>\n",
       "      <td>0.126140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò©</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you need a President too I can be one for you ...</td>\n",
       "      <td>0.701232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D√¨ cheer! Cheeeeeeeeeeeeer! salvinisciacallo C...</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ll kidnap 1000 children before I let this co...</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>omg there s more on the ballot then just the p...</td>\n",
       "      <td>0.148382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>üò±</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment_score  \\\n",
       "0  i dont want to vote for pedophile biden im sor...         0.126140   \n",
       "1  you need a President too I can be one for you ...         0.701232   \n",
       "2  D√¨ cheer! Cheeeeeeeeeeeeer! salvinisciacallo C...         0.984621   \n",
       "3  I ll kidnap 1000 children before I let this co...         0.351818   \n",
       "4  omg there s more on the ballot then just the p...         0.148382   \n",
       "\n",
       "   exclamation_points top_emoji  capitalization  profanity  \n",
       "0            0.000000         üò©        0.000000   0.000000  \n",
       "1            0.000000         üòä        0.066667   0.000000  \n",
       "2            0.014286         üòä        0.000000   0.000000  \n",
       "3            0.010101         üòä        0.111111   0.010753  \n",
       "4            0.000000         üò±        0.000000   0.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['profanity'] = df.tweet.progress_apply(check_profanity)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5019/5019 [00:01<00:00, 3893.00it/s]\n"
     ]
    }
   ],
   "source": [
    "df['subjectivity'] = df.tweet.progress_apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the replacing of extra chars\n",
    "test = \"yoooooo let's!! gooooo to the zoooo!. Wazzzzuppppp!!!. AAABBBCCC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yoo let's!! goo to the zoo!. Wazzupp!!. AABBCC\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReplaceThreeOrMore(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "üòä    2922\n",
       "üò©    1061\n",
       "üò°     711\n",
       "üò±     325\n",
       "Name: top_emoji, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.top_emoji.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a very clear and large class imbalance. In this notebook, I address the imbalance by resampling the data to be 1.5X the smallest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ax = ['Happy', 'Sad', 'Angry', 'Fearful']\n",
    "y = df.top_emoji.value_counts()\n",
    "sns.barplot(x_ax, y)\n",
    "plt.title(\"Class Imbalance\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(\"../pics/class_imbalance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dummy Classifier for Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tweet', 'sentiment_score', 'capitalization', 'profanity','exclamation_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df['top_emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24546722454672246\n"
     ]
    }
   ],
   "source": [
    "dummy_cf = DummyClassifier(strategy='uniform')\n",
    "dummy_cf.fit(X['tweet'],y)\n",
    "y_preds = dummy_cf.predict(X['tweet'])\n",
    "\n",
    "print(dummy_cf.score(X['tweet'],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y, y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "results.append(('Dummy', accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "üòä    2922\n",
       "üò©    1061\n",
       "üò°     711\n",
       "üò±     325\n",
       "Name: top_emoji, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.top_emoji.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample Data to address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "üò°    487\n",
       "üòä    487\n",
       "üò©    487\n",
       "üò±    487\n",
       "Name: top_emoji, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "cry = df[df.top_emoji == 'üò©']\n",
    "happy = df[df.top_emoji == 'üòä']\n",
    "fear = df[df.top_emoji == 'üò±']\n",
    "anger = df[df.top_emoji == 'üò°']\n",
    "\n",
    "\n",
    "cry_downsampled = resample(cry,\n",
    "                          replace=False,\n",
    "                          n_samples=int(len(fear)*1.5), # match number\n",
    "                          random_state=seed) \n",
    "\n",
    "happy_downsampled = resample(happy,\n",
    "                          replace=False,\n",
    "                          n_samples=int(len(fear)*1.5), # match number \n",
    "                          random_state=seed) \n",
    "fear_upsampled = resample(fear,\n",
    "                          replace=True, \n",
    "                          n_samples=int(len(fear)*1.5), # match number \n",
    "                          random_state=seed) \n",
    "anger_upsampled = resample(anger,\n",
    "                          replace=True,\n",
    "                          n_samples=int(len(fear)*1.5), # match number \n",
    "                          random_state=seed) \n",
    "\n",
    "df = pd.concat([cry_downsampled, happy_downsampled, fear_upsampled, anger_upsampled])\n",
    "df.top_emoji.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tweet', 'sentiment_score', 'capitalization', 'profanity','exclamation_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df['top_emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Doc.vector defaults to an average of the token vectors.\n",
    "        # https://spacy.io/api/doc#vector\n",
    "        \n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        rs = []\n",
    "        for row in data.iterrows():\n",
    "            to_add = {}\n",
    "            for item in row[1:]:\n",
    "                for ind, val in zip(item.index, item.values):\n",
    "                    to_add[ind] = val\n",
    "            rs.append(to_add)\n",
    "        return rs\n",
    "#         return [{'cap':  row['capitalization'], 'prof': row['profanity'], \n",
    "#                  'sent': row['sentiment_score'], 'excla': row['exclamation_points']} for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ItemSelector(['capitalization','sentiment_score','exclamation_points']).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = []\n",
    "for row in test.transform(X).iterrows():\n",
    "    to_add = {}\n",
    "    for item in row[1:]:\n",
    "        for ind, val in zip(item.index, item.values):\n",
    "            to_add[ind] = val\n",
    "    rs.append(to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'capitalization': 0.0,\n",
       "  'sentiment_score': 0.36153692014828176,\n",
       "  'exclamation_points': 0.0},\n",
       " {'capitalization': 0.0,\n",
       "  'sentiment_score': 0.8857328924957419,\n",
       "  'exclamation_points': 0.0}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to help in the creation of our training arrays to include custom features as well as TF IDF and Word Embeddings.\n",
    "\n",
    "- NOTE: Word embeddings hurt the score, hence it is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(input_selectors): \n",
    "    pipeline = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for pulling features from the text\n",
    "                ('text', Pipeline([\n",
    "                    ('selector', ItemSelector(key='tweet')),\n",
    "                    ('tfidf', TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n",
    "                        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                        stop_words = None, preprocessor=clean_txt)),\n",
    "                ])),\n",
    "                # Text two does not remove stopwords and tries to find bi and trigrams\n",
    "                ('text_2', Pipeline([\n",
    "                    ('selector', ItemSelector(key='tweet')),\n",
    "                    ('tfidf', TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n",
    "                        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                        ngram_range=(2, 10), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                        stop_words = None, preprocessor=clean_txt_2)),\n",
    "                ])),\n",
    "\n",
    "    #             ('embedding', Pipeline([\n",
    "    #                 ('selector', ItemSelector(key='tweet')),\n",
    "    #                 (\"mean_embeddings\", SpacyVectorTransformer(nlp))\n",
    "    #             ])),\n",
    "\n",
    "                # Pipeline for pulling metadata features\n",
    "                ('stats', Pipeline([\n",
    "                    ('selector', ItemSelector(key=input_selectors)),\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            transformer_weights={\n",
    "                'text': 1,#0.9,\n",
    "                'text_2':1,\n",
    "    #             'embedding': 1,\n",
    "                'stats': 1 #1.5,\n",
    "            },\n",
    "        ))\n",
    "    ], verbose=True)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['capitalization','profanity','sentiment_score','exclamation_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cap = create_pipeline(['capitalization'])\n",
    "pipeline_prof = create_pipeline(['profanity'])\n",
    "pipeline_sent = create_pipeline(['sentiment_score'])\n",
    "pipeline_excl = create_pipeline(['exclamation_points'])\n",
    "pipeline_all = create_pipeline(['capitalization','profanity','sentiment_score','exclamation_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   1.2s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   1.1s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   1.0s\n",
      "[Pipeline] ............. (step 1 of 1) Processing union, total=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union',\n",
       "                 FeatureUnion(transformer_list=[('text',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ItemSelector(key='tweet')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(max_df=0.2,\n",
       "                                                                                  min_df=3,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               2),\n",
       "                                                                                  preprocessor=<function clean_txt at 0x120989040>,\n",
       "                                                                                  smooth_idf=1,\n",
       "                                                                                  strip_accents='unicode',\n",
       "                                                                                  sublinear_tf=1,\n",
       "                                                                                  token_pattern='\\\\w{1,}',\n",
       "                                                                                  use_idf=1))])),\n",
       "                                                ('text_2',\n",
       "                                                 Pipeline(steps=[('sel...\n",
       "                                                                                  preprocessor=<function clean_txt_2 at 0x120967670>,\n",
       "                                                                                  smooth_idf=1,\n",
       "                                                                                  strip_accents='unicode',\n",
       "                                                                                  sublinear_tf=1,\n",
       "                                                                                  token_pattern='\\\\w{1,}',\n",
       "                                                                                  use_idf=1))])),\n",
       "                                                ('stats',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ItemSelector(key=['capitalization',\n",
       "                                                                                    'profanity',\n",
       "                                                                                    'sentiment_score',\n",
       "                                                                                    'exclamation_points'])),\n",
       "                                                                 ('stats',\n",
       "                                                                  TextStats()),\n",
       "                                                                 ('vect',\n",
       "                                                                  DictVectorizer())]))],\n",
       "                              transformer_weights={'stats': 1, 'text': 1,\n",
       "                                                   'text_2': 1}))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_cap.fit(X_train)\n",
    "pipeline_prof.fit(X_train)\n",
    "pipeline_sent.fit(X_train)\n",
    "pipeline_excl.fit(X_train)\n",
    "pipeline_all.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the shapes match: (1558, 9417) - (390, 9417)\n",
      "Checking that the shapes match: (1558, 9417) - (390, 9417)\n",
      "Checking that the shapes match: (1558, 9417) - (390, 9417)\n",
      "Checking that the shapes match: (1558, 9417) - (390, 9417)\n",
      "Checking that the shapes match: (1558, 9420) - (390, 9420)\n",
      "CPU times: user 5.51 s, sys: 31.2 ms, total: 5.54 s\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_vec_cap = pipeline_cap.transform(X_train)\n",
    "test_vec_cap = pipeline_cap.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_cap.shape, test_vec_cap.shape))\n",
    "\n",
    "train_vec_prof = pipeline_prof.transform(X_train)\n",
    "test_vec_prof = pipeline_prof.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_prof.shape, test_vec_prof.shape))\n",
    "\n",
    "train_vec_sent = pipeline_sent.transform(X_train)\n",
    "test_vec_sent = pipeline_sent.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_sent.shape, test_vec_sent.shape))\n",
    "\n",
    "train_vec_excl = pipeline_excl.transform(X_train)\n",
    "test_vec_excl = pipeline_excl.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_excl.shape, test_vec_excl.shape))\n",
    "\n",
    "train_vec_all = pipeline_all.transform(X_train)\n",
    "test_vec_all = pipeline_all.transform(X_test)\n",
    "print(\"Checking that the shapes match: %s - %s\" % (train_vec_all.shape, test_vec_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = [train_vec_cap, train_vec_prof, train_vec_sent, train_vec_excl, train_vec_all]\n",
    "tests = [test_vec_cap, test_vec_prof, test_vec_sent, test_vec_excl, test_vec_all]\n",
    "labels = ['capitalization', 'profanity', 'sentiment_score', 'exclamation_points', 'all_custom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Overarching Function for Iterative Modeling\n",
    "- Takes in a model\n",
    "- Fits that model against all the different train/test vecs with dif features\n",
    "- prints out accuracy and description of what train/test vec worked best\n",
    "- prints out confusion matrix and classification report for best version of the model\n",
    "- Returns best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(model, model_name):\n",
    "    res = []\n",
    "    for train, test, label in zip(trains, tests, labels):\n",
    "        if type(model) == xgboost.sklearn.XGBClassifier:\n",
    "            model.fit(train, y_train, eval_metric='mlogloss')\n",
    "        else:\n",
    "            model.fit(train, y_train)\n",
    "        test_preds = model.predict(test)\n",
    "        accuracy = accuracy_score(y_test, test_preds)\n",
    "        res.append({'label': label, 'score': accuracy, 'test_preds': test_preds})\n",
    "    res = sorted(res, key = lambda x: x['score'], reverse=True)\n",
    "    print('RESULTS')\n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    print(f\"{model_name} with {res[0]['label']} features performed the best with an accuracy of {res[0]['score']}\")\n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, res[0]['test_preds']))\n",
    "    print('----------------------------------------')\n",
    "    print(confusion_matrix(y_test, res[0]['test_preds']))\n",
    "    return res[0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to use in the optimization problem.\n",
    "\n",
    "    - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
    "      'saga' are faster for large ones.\n",
    "    - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
    "      handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
    "      schemes.\n",
    "    - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
    "      'liblinear' and 'saga' handle L1 penalty.\n",
    "    - 'liblinear' might be slower in LogisticRegressionCV because it does\n",
    "      not handle warm-starting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "log reg with sentiment_score features performed the best with an accuracy of 0.7051282051282052\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.78      0.87      0.82        98\n",
      "           üò°       0.70      0.71      0.71        97\n",
      "           üò©       0.56      0.41      0.47        98\n",
      "           üò±       0.73      0.84      0.78        97\n",
      "\n",
      "    accuracy                           0.71       390\n",
      "   macro avg       0.69      0.71      0.69       390\n",
      "weighted avg       0.69      0.71      0.69       390\n",
      "\n",
      "----------------------------------------\n",
      "[[85  6  7  0]\n",
      " [ 7 69 12  9]\n",
      " [16 21 40 21]\n",
      " [ 1  2 13 81]]\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegressionCV(solver='newton-cg', cv=10, penalty='l2', Cs = [.001,.01,.1,1,10,100], \n",
    "                                    max_iter=10000, verbose=True, n_jobs=-1, scoring='f1', multi_class='ovr',\n",
    "                                class_weight='balanced')\n",
    "results.append(('log reg', get_model_results(lr_clf, 'log reg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583), ('log reg', 0.7051282051282052)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "linear svc with sentiment_score features performed the best with an accuracy of 0.7153846153846154\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.77      0.88      0.82        98\n",
      "           üò°       0.70      0.71      0.70        97\n",
      "           üò©       0.60      0.44      0.51        98\n",
      "           üò±       0.76      0.84      0.79        97\n",
      "\n",
      "    accuracy                           0.72       390\n",
      "   macro avg       0.70      0.72      0.71       390\n",
      "weighted avg       0.70      0.72      0.71       390\n",
      "\n",
      "----------------------------------------\n",
      "[[86  7  5  0]\n",
      " [ 9 69 12  7]\n",
      " [16 20 43 19]\n",
      " [ 1  3 12 81]]\n"
     ]
    }
   ],
   "source": [
    "sv_clf = LinearSVC(C=1, class_weight='balanced', multi_class='ovr', random_state=seed) \n",
    "results.append(('linear svc', get_model_results(sv_clf, 'linear svc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "svc with sentiment_score features performed the best with an accuracy of 0.7769230769230769\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.84      0.92      0.88        98\n",
      "           üò°       0.78      0.69      0.73        97\n",
      "           üò©       0.67      0.64      0.66        98\n",
      "           üò±       0.81      0.86      0.83        97\n",
      "\n",
      "    accuracy                           0.78       390\n",
      "   macro avg       0.77      0.78      0.77       390\n",
      "weighted avg       0.77      0.78      0.77       390\n",
      "\n",
      "----------------------------------------\n",
      "[[90  1  7  0]\n",
      " [ 6 67 13 11]\n",
      " [11 15 63  9]\n",
      " [ 0  3 11 83]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=15, class_weight='balanced', kernel='rbf', gamma='scale')\n",
    "results.append(('svc', get_model_results(svc, 'svc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('svc', 0.7769230769230769)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "rfc with all_custom features performed the best with an accuracy of 0.7692307692307693\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.79      0.91      0.85        98\n",
      "           üò°       0.76      0.73      0.74        97\n",
      "           üò©       0.67      0.65      0.66        98\n",
      "           üò±       0.85      0.78      0.82        97\n",
      "\n",
      "    accuracy                           0.77       390\n",
      "   macro avg       0.77      0.77      0.77       390\n",
      "weighted avg       0.77      0.77      0.77       390\n",
      "\n",
      "----------------------------------------\n",
      "[[89  4  5  0]\n",
      " [ 8 71 12  6]\n",
      " [14 13 64  7]\n",
      " [ 1  6 14 76]]\n"
     ]
    }
   ],
   "source": [
    "rfc_clf = RandomForestClassifier(n_estimators=400, random_state=seed,n_jobs=-1,\n",
    "                                 class_weight='balanced',criterion='entropy' )\n",
    "results.append(('rfc', get_model_results(rfc_clf, 'rfc')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('svc', 0.7769230769230769),\n",
       " ('rfc', 0.7692307692307693)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MN Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "mn bayes with sentiment_score features performed the best with an accuracy of 0.5923076923076923\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.49      0.86      0.62        98\n",
      "           üò°       0.71      0.59      0.64        97\n",
      "           üò©       0.47      0.41      0.43        98\n",
      "           üò±       0.94      0.52      0.67        97\n",
      "\n",
      "    accuracy                           0.59       390\n",
      "   macro avg       0.65      0.59      0.59       390\n",
      "weighted avg       0.65      0.59      0.59       390\n",
      "\n",
      "----------------------------------------\n",
      "[[84  5  9  0]\n",
      " [24 57 15  1]\n",
      " [47  9 40  2]\n",
      " [16  9 22 50]]\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "mnb_clf = MultinomialNB() \n",
    "results.append(('mn bayes', get_model_results(mnb_clf, 'mn bayes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('svc', 0.7769230769230769),\n",
       " ('rfc', 0.7692307692307693),\n",
       " ('mn bayes', 0.5923076923076923)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "bernoulli bayes with profanity features performed the best with an accuracy of 0.39487179487179486\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.36      0.83      0.51        98\n",
      "           üò°       1.00      0.13      0.24        97\n",
      "           üò©       0.32      0.46      0.38        98\n",
      "           üò±       1.00      0.15      0.27        97\n",
      "\n",
      "    accuracy                           0.39       390\n",
      "   macro avg       0.67      0.39      0.35       390\n",
      "weighted avg       0.67      0.39      0.35       390\n",
      "\n",
      "----------------------------------------\n",
      "[[81  0 17  0]\n",
      " [50 13 34  0]\n",
      " [53  0 45  0]\n",
      " [38  0 44 15]]\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli Naive Bayes\n",
    "bb_clf = BernoulliNB() \n",
    "results.append(('bernoulli bayes', get_model_results(bb_clf, 'bernoulli bayes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('svc', 0.7769230769230769),\n",
       " ('rfc', 0.7692307692307693),\n",
       " ('mn bayes', 0.5923076923076923),\n",
       " ('bernoulli bayes', 0.39487179487179486)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "pac with all_custom features performed the best with an accuracy of 0.6846153846153846\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.71      0.76      0.73        98\n",
      "           üò°       0.71      0.69      0.70        97\n",
      "           üò©       0.51      0.45      0.48        98\n",
      "           üò±       0.78      0.85      0.81        97\n",
      "\n",
      "    accuracy                           0.68       390\n",
      "   macro avg       0.68      0.69      0.68       390\n",
      "weighted avg       0.68      0.68      0.68       390\n",
      "\n",
      "----------------------------------------\n",
      "[[74  8 16  0]\n",
      " [10 67 13  7]\n",
      " [19 19 44 16]\n",
      " [ 1  1 13 82]]\n"
     ]
    }
   ],
   "source": [
    "#PassiveAggresive Classifier\n",
    "pac_clf = PassiveAggressiveClassifier() \n",
    "results.append(('pac', get_model_results(pac_clf, 'pac')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('svc', 0.7769230769230769),\n",
       " ('rfc', 0.7692307692307693),\n",
       " ('mn bayes', 0.5923076923076923),\n",
       " ('bernoulli bayes', 0.39487179487179486),\n",
       " ('pac', 0.6846153846153846)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "xgboost with all_custom features performed the best with an accuracy of 0.7948717948717948\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.87      0.92      0.89        98\n",
      "           üò°       0.76      0.80      0.78        97\n",
      "           üò©       0.73      0.60      0.66        98\n",
      "           üò±       0.81      0.86      0.83        97\n",
      "\n",
      "    accuracy                           0.79       390\n",
      "   macro avg       0.79      0.80      0.79       390\n",
      "weighted avg       0.79      0.79      0.79       390\n",
      "\n",
      "----------------------------------------\n",
      "[[90  2  5  1]\n",
      " [ 4 78  6  9]\n",
      " [10 19 59 10]\n",
      " [ 0  3 11 83]]\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_jobs=-1)\n",
    "results.append(('xgboost', get_model_results(xg, 'xgboost')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dummy', 0.2604104403267583),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('svc', 0.7769230769230769),\n",
       " ('rfc', 0.7692307692307693),\n",
       " ('mn bayes', 0.5923076923076923),\n",
       " ('bernoulli bayes', 0.39487179487179486),\n",
       " ('pac', 0.6846153846153846),\n",
       " ('xgboost', 0.7948717948717948)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "-------------------------------------------------------------------------------------------------\n",
      "voting with sentiment_score features performed the best with an accuracy of 0.7512820512820513\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           üòä       0.76      0.93      0.83        98\n",
      "           üò°       0.75      0.72      0.74        97\n",
      "           üò©       0.64      0.52      0.57        98\n",
      "           üò±       0.84      0.84      0.84        97\n",
      "\n",
      "    accuracy                           0.75       390\n",
      "   macro avg       0.75      0.75      0.74       390\n",
      "weighted avg       0.75      0.75      0.74       390\n",
      "\n",
      "----------------------------------------\n",
      "[[91  3  4  0]\n",
      " [ 7 70 13  7]\n",
      " [21 17 51  9]\n",
      " [ 1  3 12 81]]\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('logreg', lr_clf), ('svm_linear', sv_clf), ('pass_aggr', pac_clf),\n",
    "                            ('svc', svc), ('xgboost', xg), ('rfc', rfc_clf),\n",
    "                            ('mnbayes', mnb_clf),('berbayes', bb_clf)], #(\n",
    "                voting='hard', verbose=1, n_jobs= -1)\n",
    "results.append(('voting', get_model_results(voting_clf, 'voting')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xgboost', 0.7948717948717948),\n",
       " ('svc', 0.7769230769230769),\n",
       " ('rfc', 0.7692307692307693),\n",
       " ('voting', 0.7512820512820513),\n",
       " ('linear svc', 0.7153846153846154),\n",
       " ('log reg', 0.7051282051282052),\n",
       " ('pac', 0.6846153846153846),\n",
       " ('mn bayes', 0.5923076923076923),\n",
       " ('bernoulli bayes', 0.39487179487179486),\n",
       " ('Dummy', 0.2604104403267583)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart of Different Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[0] for x in results]\n",
    "y = [x[1] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x,y)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Model Results\", fontsize=20)\n",
    "plt.savefig(\"../pics/model_performances.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
